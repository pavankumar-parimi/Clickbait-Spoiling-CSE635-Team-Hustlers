{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions\n",
        "!pip install transformers\n",
        "!pip install rank-bm25\n",
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnFpcArnuWH5",
        "outputId": "834c562a-9266-411a-f602-a55199f3ccc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting pyahocorasick\n",
            "  Downloading pyahocorasick-2.0.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting anyascii\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 KB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rank-bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from rank-bm25) (1.22.4)\n",
            "Installing collected packages: rank-bm25\n",
            "Successfully installed rank-bm25-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEuKCCwjtUJB"
      },
      "outputs": [],
      "source": [
        "# Read and Split the given Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocessing"
      ],
      "metadata": {
        "id": "tSus7zub_fEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read data from the json files\n",
        "train_df = pd.read_json(\"train.jsonl\", lines = True)\n",
        "validation_df = pd.read_json(\"validation.jsonl\", lines = True)\n",
        "\n",
        "print(\"train data shape:\",train_df.shape)\n",
        "print(\"validation data shape:\",validation_df.shape)\n",
        "\n",
        "# Merge the complete data to divide the data train, test and validation\n",
        "\n",
        "total_df = pd.concat([train_df, validation_df], ignore_index = True)\n",
        "print(\"total data shape:\",total_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igrPZ3HCttP6",
        "outputId": "001f746e-1515-4a78-c317-1bb72299ff2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data shape: (3200, 14)\n",
            "validation data shape: (800, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_df = total_df[[\"uuid\", \"postText\", \"targetParagraphs\", \"spoiler\", \"tags\",\"targetTitle\",\"targetDescription\",\"spoilerPositions\",\"provenance\"]]\n",
        "total_df.rename(columns={\"postText\":\"clickbait\", \"targetParagraphs\":\"document\", \"tags\":\"type\"}, inplace = True)"
      ],
      "metadata": {
        "id": "sRJqlSNKudH5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c089eed5-d45d-4932-9bfd-e8143b57bdde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-2dc82af6a2d3>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  total_df.rename(columns={\"postText\":\"clickbait\", \"targetParagraphs\":\"document\", \"tags\":\"type\"}, inplace = True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing and BM25 Implementation"
      ],
      "metadata": {
        "id": "exuMDHm3_urx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to Make values in Spoiler_Type(list to string)\n",
        "def list_to_string(spoiler_type):\n",
        "  if spoiler_type[0] == \"phrase\":\n",
        "    return 0\n",
        "  elif spoiler_type[0] == \"passage\":\n",
        "    return 1\n",
        "  elif spoiler_type[0] == \"multi\":\n",
        "    return 2\n",
        "\n",
        "total_df[\"type\"] = total_df[\"type\"].apply(list_to_string)\n",
        "\n",
        "total_df_bkp = total_df.copy()\n",
        "total_df = total_df[total_df['type']==1]\n",
        "total_df.reset_index(drop=True,inplace=True)"
      ],
      "metadata": {
        "id": "AEHMmyVav-3D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f02f5280-e5e2-4c16-977c-f45e6571d56a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-5d26f8770338>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  total_df[\"type\"] = total_df[\"type\"].apply(list_to_string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def append_text(x):\n",
        "  if(x['targetDescription']!=None):\n",
        "    x['document'].append(x['targetTitle'])\n",
        "  return x['document']"
      ],
      "metadata": {
        "id": "JnXo0A8_-x8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_df['document'] = total_df.apply(append_text,axis=1)"
      ],
      "metadata": {
        "id": "N1Dka8lv-mJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_human_spoiler(x):\n",
        "  return x['provenance']['humanSpoiler']"
      ],
      "metadata": {
        "id": "y-rGWEd4BPf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_corpus(x):\n",
        "  return [sen.split(\" \") for sen in x]"
      ],
      "metadata": {
        "id": "czDyyE9Om0G7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_df['tokenized_doc'] = total_df['document'].apply(tokenize_corpus)"
      ],
      "metadata": {
        "id": "11Eqb6l4OSjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rank_bm25 import BM25Okapi\n",
        "total_df['tokenized_doc_bm25'] = total_df['tokenized_doc'].apply(lambda x: BM25Okapi(x))"
      ],
      "metadata": {
        "id": "z3PaBGZiPQit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_df.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "OxPMxUmPQe8F",
        "outputId": "9ab740d6-0c57-45bc-f3cb-6457a9f659e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   uuid  \\\n",
              "0  0af11f6b-c889-4520-9372-66ba25cb7657   \n",
              "1  12e3034e-a98f-4cd2-8773-3f7974161c45   \n",
              "\n",
              "                                           clickbait  \\\n",
              "0  [Wes Welker Wanted Dinner With Tom Brady, But ...   \n",
              "1  [What happens if your new AirPods get lost or ...   \n",
              "\n",
              "                                            document  \\\n",
              "0  [It’ll be just like old times this weekend for...   \n",
              "1  [One of the biggest surprise announcements at ...   \n",
              "\n",
              "                                             spoiler  type  \\\n",
              "0              [how about that morning we go throw?]     1   \n",
              "1  [Apple says that if AirPods are lost or stolen...     1   \n",
              "\n",
              "                                         targetTitle  \\\n",
              "0  Wes Welker Wanted Dinner With Tom Brady, But P...   \n",
              "1  Here's what happens if your Apple AirPods get ...   \n",
              "\n",
              "                                   targetDescription        spoilerPositions  \\\n",
              "0  It'll be just like old times this weekend for ...  [[[3, 151], [3, 186]]]   \n",
              "1  One of the first questions we had about Apple'...    [[[4, 0], [4, 110]]]   \n",
              "\n",
              "                                          provenance  \\\n",
              "0  {'source': 'anonymized', 'humanSpoiler': 'They...   \n",
              "1  {'source': 'anonymized', 'humanSpoiler': 'No',...   \n",
              "\n",
              "                                       tokenized_doc  \\\n",
              "0  [[It’ll, be, just, like, old, times, this, wee...   \n",
              "1  [[One, of, the, biggest, surprise, announcemen...   \n",
              "\n",
              "                               tokenized_doc_bm25  \\\n",
              "0  <rank_bm25.BM25Okapi object at 0x7fadeea663d0>   \n",
              "1  <rank_bm25.BM25Okapi object at 0x7fadeea66370>   \n",
              "\n",
              "                                 tokenized_clickbait  \\\n",
              "0  [[Wes, Welker, Wanted, Dinner, With, Tom, Brad...   \n",
              "1  [[What, happens, if, your, new, AirPods, get, ...   \n",
              "\n",
              "                                         dm25_scores  \\\n",
              "0  [2.6778664701405854, 0.3312983287185408, 0.483...   \n",
              "1  [0.0, 2.0895428421687177, 3.821048370397315, 0...   \n",
              "\n",
              "                                     output_sentence  \\\n",
              "0  [Wes Welker Wanted Dinner With Tom Brady, But ...   \n",
              "1  [Here's what happens if your Apple AirPods get...   \n",
              "\n",
              "                                         bm25_scores  \n",
              "0  [2.6778664701405854, 0.3312983287185408, 0.483...  \n",
              "1  [0.0, 2.0895428421687177, 3.821048370397315, 0...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9aaf86d0-e0aa-41e1-866a-a7a4313484d6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uuid</th>\n",
              "      <th>clickbait</th>\n",
              "      <th>document</th>\n",
              "      <th>spoiler</th>\n",
              "      <th>type</th>\n",
              "      <th>targetTitle</th>\n",
              "      <th>targetDescription</th>\n",
              "      <th>spoilerPositions</th>\n",
              "      <th>provenance</th>\n",
              "      <th>tokenized_doc</th>\n",
              "      <th>tokenized_doc_bm25</th>\n",
              "      <th>tokenized_clickbait</th>\n",
              "      <th>dm25_scores</th>\n",
              "      <th>output_sentence</th>\n",
              "      <th>bm25_scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0af11f6b-c889-4520-9372-66ba25cb7657</td>\n",
              "      <td>[Wes Welker Wanted Dinner With Tom Brady, But ...</td>\n",
              "      <td>[It’ll be just like old times this weekend for...</td>\n",
              "      <td>[how about that morning we go throw?]</td>\n",
              "      <td>1</td>\n",
              "      <td>Wes Welker Wanted Dinner With Tom Brady, But P...</td>\n",
              "      <td>It'll be just like old times this weekend for ...</td>\n",
              "      <td>[[[3, 151], [3, 186]]]</td>\n",
              "      <td>{'source': 'anonymized', 'humanSpoiler': 'They...</td>\n",
              "      <td>[[It’ll, be, just, like, old, times, this, wee...</td>\n",
              "      <td>&lt;rank_bm25.BM25Okapi object at 0x7fadeea663d0&gt;</td>\n",
              "      <td>[[Wes, Welker, Wanted, Dinner, With, Tom, Brad...</td>\n",
              "      <td>[2.6778664701405854, 0.3312983287185408, 0.483...</td>\n",
              "      <td>[Wes Welker Wanted Dinner With Tom Brady, But ...</td>\n",
              "      <td>[2.6778664701405854, 0.3312983287185408, 0.483...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12e3034e-a98f-4cd2-8773-3f7974161c45</td>\n",
              "      <td>[What happens if your new AirPods get lost or ...</td>\n",
              "      <td>[One of the biggest surprise announcements at ...</td>\n",
              "      <td>[Apple says that if AirPods are lost or stolen...</td>\n",
              "      <td>1</td>\n",
              "      <td>Here's what happens if your Apple AirPods get ...</td>\n",
              "      <td>One of the first questions we had about Apple'...</td>\n",
              "      <td>[[[4, 0], [4, 110]]]</td>\n",
              "      <td>{'source': 'anonymized', 'humanSpoiler': 'No',...</td>\n",
              "      <td>[[One, of, the, biggest, surprise, announcemen...</td>\n",
              "      <td>&lt;rank_bm25.BM25Okapi object at 0x7fadeea66370&gt;</td>\n",
              "      <td>[[What, happens, if, your, new, AirPods, get, ...</td>\n",
              "      <td>[0.0, 2.0895428421687177, 3.821048370397315, 0...</td>\n",
              "      <td>[Here's what happens if your Apple AirPods get...</td>\n",
              "      <td>[0.0, 2.0895428421687177, 3.821048370397315, 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9aaf86d0-e0aa-41e1-866a-a7a4313484d6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9aaf86d0-e0aa-41e1-866a-a7a4313484d6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9aaf86d0-e0aa-41e1-866a-a7a4313484d6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_df['tokenized_clickbait'] = total_df['clickbait'].apply(tokenize_corpus)"
      ],
      "metadata": {
        "id": "eDMGsiQEQ5Ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bm25_scores(x):\n",
        "  scores = x['tokenized_doc_bm25'].get_scores(x['tokenized_clickbait'][0])\n",
        "  # print(scores)\n",
        "  return scores"
      ],
      "metadata": {
        "id": "_y0TzuqEYIiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_df['bm25_scores'] = total_df.apply(get_bm25_scores,axis=1)"
      ],
      "metadata": {
        "id": "ENF5h2RdRLqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_spoiler(x):\n",
        "  output_spoiler = x['tokenized_doc_bm25'].get_top_n(x['tokenized_clickbait'][0],x['document'],n=1)\n",
        "  # print(output_spoiler)\n",
        "  return output_spoiler"
      ],
      "metadata": {
        "id": "T4cd9TEEdW_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_df['output_sentence'] = total_df.apply(get_spoiler,axis=1)"
      ],
      "metadata": {
        "id": "KqIJle8VZrIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation metric"
      ],
      "metadata": {
        "id": "Vd2he_pi_y4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BLEU\n",
        "\n",
        "import evaluate\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "from rank_bm25 import BM25Okapi\n",
        "count = 0\n",
        "results = 0\n",
        "\n",
        "for index, row in total_df.iterrows():\n",
        "\n",
        "  corpus = row[\"document\"]\n",
        "\n",
        "  tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "\n",
        "  bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "  query = row[\"clickbait\"][0]\n",
        "  tokenized_query = query.split(\" \")\n",
        "\n",
        "  doc_scores = bm25.get_scores(tokenized_query)\n",
        "\n",
        "  doc_scores = list(doc_scores)\n",
        "  sentence_index = doc_scores.index(max(doc_scores))\n",
        "\n",
        "  predicted_sentence = [row[\"document\"][sentence_index]]\n",
        "\n",
        "\n",
        "  # Bleu score\n",
        "  predictions = predicted_sentence\n",
        "  references = [[row['spoiler']]]\n",
        "  results += bleu.compute(predictions=predictions, references=references).get(\"bleu\")\n",
        "  count += 1\n",
        "\n",
        "  if count == 100:\n",
        "    break\n",
        "\n",
        "bleu_score = results/count\n",
        "print(\"BLEU Score: \", bleu_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "3bg7Ess_wH6U",
        "outputId": "09f32509-91f9-48eb-8946-212ebf01df33"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-34be6093631a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bleu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrank_bm25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBM25Okapi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'evaluate'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# METEOR\n",
        "\n",
        "import evaluate\n",
        "meteor = evaluate.load('meteor')\n",
        "from rank_bm25 import BM25Okapi\n",
        "count = 0\n",
        "results = 0\n",
        "\n",
        "for index, row in total_df.iterrows():\n",
        "\n",
        "  corpus = row[\"document\"]\n",
        "\n",
        "  tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "\n",
        "  bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "  query = row[\"clickbait\"][0]\n",
        "  tokenized_query = query.split(\" \")\n",
        "\n",
        "  doc_scores = bm25.get_scores(tokenized_query)\n",
        "\n",
        "  doc_scores = list(doc_scores)\n",
        "  sentence_index = doc_scores.index(max(doc_scores))\n",
        "\n",
        "  predicted_sentence = [row[\"document\"][sentence_index]]\n",
        "\n",
        "\n",
        "  # Meteor score\n",
        "  predictions = [f'\"{predicted_sentence}\"']\n",
        "  spoiler = row['spoiler']\n",
        "  references = [\n",
        "                  [f'\"{spoiler}\"'], \n",
        "    ]\n",
        "  print(\"1. predictions: \", predicted_sentence)\n",
        "  print(\"2. spoilers: \", spoiler)\n",
        "  print(\"\\n\")\n",
        "  results += meteor.compute(predictions=predictions, references=references).get(\"meteor\")\n",
        "  count += 1\n",
        "\n",
        "\n",
        "  if count == 10:\n",
        "    break\n",
        "\n",
        "meteor_score = results/count\n",
        "print(\"METEOR Score: \", meteor_score)\n"
      ],
      "metadata": {
        "id": "aGq9jqLM9ViJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "from rank_bm25 import BM25Okapi\n",
        "bertscore = load(\"bertscore\")\n",
        "\n",
        "results = 0\n",
        "total_precision = 0\n",
        "total_recall = 0\n",
        "total_f1 = 0\n",
        "\n",
        "count = 0\n",
        "\n",
        "for index, row in total_df.iterrows():\n",
        "\n",
        "  corpus = row[\"document\"]\n",
        "\n",
        "  tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "\n",
        "  bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "  query = row[\"clickbait\"][0]\n",
        "  tokenized_query = query.split(\" \")\n",
        "\n",
        "  doc_scores = bm25.get_scores(tokenized_query)\n",
        "\n",
        "  doc_scores = list(doc_scores)\n",
        "  sentence_index = doc_scores.index(max(doc_scores))\n",
        "\n",
        "  predicted_sentence = [row[\"document\"][sentence_index]]\n",
        "\n",
        "\n",
        "  # BERT score\n",
        "  predictions = [f'\"{predicted_sentence}\"']\n",
        "  spoiler = row[\"spoiler\"]\n",
        "  references = [\n",
        "                  f'\"{spoiler}\"'\n",
        "    ]\n",
        "\n",
        "  print(\"1. predictions: \", predicted_sentence)\n",
        "  print(\"2. spoilers: \", spoiler)\n",
        "  print(\"\\n\")\n",
        "\n",
        "  results = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
        "  total_precision += results.get(\"precision\")[0]\n",
        "  total_recall += results.get(\"recall\")[0]\n",
        "  total_f1 += results.get(\"f1\")[0]\n",
        "  print(count)\n",
        "  count += 1\n",
        "\n",
        "  if count == 10:\n",
        "    break\n",
        "\n",
        "avg_precision = total_precision/count\n",
        "avg_recall = total_recall/count\n",
        "avg_f1 = total_f1/count\n",
        "\n",
        "print(\"Avg. Precision value: \", avg_precision)\n",
        "print(\"Avg. Recall value: \", avg_recall)\n",
        "print(\"Avg. F1 value: \", avg_f1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WddXMMEQznte",
        "outputId": "928ae2ea-a3eb-4553-d2a5-d020b906f812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. predictions:  ['Wes Welker Wanted Dinner With Tom Brady, But Patriots QB Had A Better Idea']\n",
            "2. spoilers:  ['how about that morning we go throw?']\n",
            "\n",
            "\n",
            "0\n",
            "1. predictions:  [\"Here's what happens if your Apple AirPods get lost or stolen\"]\n",
            "2. spoilers:  [\"Apple says that if AirPods are lost or stolen, you'll have to buy new ones, just like any other Apple product.\"]\n",
            "\n",
            "\n",
            "1\n",
            "1. predictions:  ['The Reason Why Gabor Kiraly Wears THOSE Trackie Bottoms']\n",
            "2. spoilers:  ['\"The more good games I had in them, the more I got used to them.']\n",
            "\n",
            "\n",
            "2\n",
            "1. predictions:  ['\"It was cold and very foggy, the temperature was around -10 degrees Celsius,\" said Hänninen. \"When the clouds began to break, there were rainbow colours in the sky and a halo spanning 360 degrees! It was worth taking a picture or two.\"']\n",
            "2. spoilers:  ['rainbow colours in the sky and a halo spanning 360 degrees']\n",
            "\n",
            "\n",
            "3\n",
            "1. predictions:  ['Should I Drink Red Wine?']\n",
            "2. spoilers:  ['Red wine is clearly the drink of choice if you are doing light to moderate drinking for your health, and daily consumption just before or with the evening meal may be the most protective pattern,\" O’Keefe says']\n",
            "\n",
            "\n",
            "4\n",
            "1. predictions:  [\"Target's $20 million answer to transgender bathroom boycott - Aug. 17...\"]\n",
            "2. spoilers:  ['says it will spend $20 million to expand bathroom options at all of its U.S. stores']\n",
            "\n",
            "\n",
            "5\n",
            "1. predictions:  [\"China invited a reporter to hit their new glass bridge with a sledgehammer to prove it's safe. He proved something.\"]\n",
            "2. spoilers:  [\"Although Simmons' first blow shattered the glass, he was unable to structurally compromise the underlying layers even after he let loose on it dozens of times.\"]\n",
            "\n",
            "\n",
            "6\n",
            "1. predictions:  ['Instagram Just Killed This Feature']\n",
            "2. spoilers:  [\"the feature that allowed you to see a map of where a given user's photos were taken (if they designated a location for the photo).\"]\n",
            "\n",
            "\n",
            "7\n",
            "1. predictions:  [\"Subways Are Full of Bacteria But Don't Freak Out\"]\n",
            "2. spoilers:  ['scientists didn’t find pathogenic organisms that typically cause sickness or antibiotic-resistant genes']\n",
            "\n",
            "\n",
            "8\n",
            "1. predictions:  ['This Theory Explains Why Harry Doesn’t Have A Lot Of Gryffindor Friends']\n",
            "2. spoilers:  ['because of the war with Voldemort.']\n",
            "\n",
            "\n",
            "9\n",
            "Avg. Precision value:  0.845742130279541\n",
            "Avg. Recall value:  0.8499876260757446\n",
            "Avg. F1 value:  0.8475351810455323\n"
          ]
        }
      ]
    }
  ]
}